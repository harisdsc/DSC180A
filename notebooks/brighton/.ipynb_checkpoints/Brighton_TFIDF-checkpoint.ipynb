{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ed8d263-ded8-48aa-9e8d-7f8256f457df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/chc099/.local/lib/python3.11/site-packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9effafa-54d7-4f6f-aaf7-df266cbc7a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "sys.path.append(repo_root)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "import re\n",
    "from typing import List, Tuple, Iterable, Optional\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix, PrecisionRecallDisplay\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import holidays\n",
    "from datetime import timedelta\n",
    "from pandarallel import pandarallel\n",
    "from src.feature_extraction.date_amnt_feats import create_date_feats, create_amnt_feats\n",
    "from src.feature_extraction.holiday_feats import add_custom_holidays, holiday_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e0375e-ae1e-4043-bd85-84c980702d97",
   "metadata": {},
   "source": [
    "## Week 2 (Train Test Split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9701f4e2-c832-4eca-9f52-5641654eb161",
   "metadata": {},
   "outputs": [],
   "source": [
    "inflow = pd.read_parquet('/uss/hdsi-prismdata/q1-ucsd-inflows.pqt')\n",
    "outflow = pd.read_parquet('/uss/hdsi-prismdata/q1-ucsd-outflows.pqt')\n",
    "\n",
    "# remove rows where memo = category\n",
    "outflow = outflow[outflow['memo'] != outflow['category']]\n",
    "\n",
    "outflow_ids = set(outflow[\"prism_consumer_id\"].unique())\n",
    "inflow_ids = set(inflow[\"prism_consumer_id\"].unique())\n",
    "\n",
    "in_not_out = inflow_ids - outflow_ids\n",
    "out_not_in = outflow_ids - inflow_ids\n",
    "\n",
    "#consumers in both inflow and outflow\n",
    "consumers_both = sorted(set(inflow[\"prism_consumer_id\"]).intersection(outflow[\"prism_consumer_id\"]))\n",
    "\n",
    "#80-20 train test split\n",
    "train_ids, test_ids = train_test_split(consumers_both, test_size=0.2, random_state=42)\n",
    "\n",
    "inflow_train = inflow[inflow[\"prism_consumer_id\"].isin(train_ids)]\n",
    "inflow_test  = inflow[inflow[\"prism_consumer_id\"].isin(test_ids)]\n",
    "\n",
    "outflow_train = outflow[outflow[\"prism_consumer_id\"].isin(train_ids)]\n",
    "outflow_test  = outflow[outflow[\"prism_consumer_id\"].isin(test_ids)]\n",
    "\n",
    "# print(f'Inflow_train: {inflow_train[\"amount\"].median()}\\nInflow_test: {inflow_test[\"amount\"].median()}\\nOutflow_train: {outflow_train[\"amount\"].median()}\\nOutflow_test: {outflow_test[\"amount\"].median()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfda9a9a-90ba-429c-a098-9bf04f3cdb16",
   "metadata": {},
   "source": [
    "## Week 3 (Cleaning Memos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bc9e09-fbaf-4625-868c-77adb0486d32",
   "metadata": {},
   "source": [
    "### Remove Observed Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddfd08a9-0a4d-4941-8c10-2da7504b5406",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use train_memos.txt to observe patterns from original outflow_train\n",
    "# unique_memos = np.sort(outflow_train[outflow_train['memo']!=outflow_train['category']]['memo'].str.lower().unique())\n",
    "# np.savetxt(\"train_memos.txt\", unique_memos, fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7d1d280-9300-4689-bfde-9dfe9afd1cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = outflow_train[outflow_train['memo']!=outflow_train['category']]['memo'].str.lower()\n",
    "clean = m.copy(deep = True)\n",
    "\n",
    "websites = re.compile(r'\\b(?:www\\.)?([a-wy-z0-9]+)[.\\s](com|com|net|org|gov)\\b', flags=re.IGNORECASE)\n",
    "\n",
    "# extract website domain\n",
    "def extract_domain(text):\n",
    "    m = websites.search(text)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "clean = clean.apply(extract_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45224886-6d34-4501-8462-bdcf84d8ebd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed count: 605120\n"
     ]
    }
   ],
   "source": [
    "patterns = [r'^#\\d*x*\\s', #starting number signs with following 0 or more digits inlcuding x then space\n",
    "            r'\\(?(?:\\d|x){3}\\)?(?:\\s|-)(?:\\d|x){3}(?:\\s|-)(?:\\d|x){4}', # phone numbers in various formats\n",
    "            r'(?:\\s|^)[^A-Za-z0-9]?x+(?:[^A-Za-z0-9]+x+)*(?:\\s|$)', #various sequences of trailing x\n",
    "            r'\\b[^A-Za-z0-9](al|ak|az|ar|ca|co|ct|de|fl|ga|hi|id|il|ia|ks|ky|me|md|ma|mi|mn|ms|mo|mt|ne|nv|nh|nj|nm|ny|nc|nd|oh|ok|or|pa|ri|sc|sd|tn|tx|ut|vt|va|wa|wv|wi|wy|dc)(?![A-Za-z0-9])\\b',\n",
    "            #state abbreviations besides 'in' bc ex: in n out\n",
    "            r'\\bin$', #ending 'in' state and la\n",
    "            r'(?:in)?\\scard\\s\\d{2}\\s?',\n",
    "            # format ex: card 20 unless in card 20\n",
    "            r'\\b\\d{2}[/-]\\d{2}(?:[/-]\\d{2,4})?\\b', #dates\n",
    "            r'\\d{2}\\:\\d{2}(?:\\:\\d{2})?[ap]?m?', #time stamps\n",
    "            r'(?:date\\s)?\\%\\%(?:\\smcc)?', #format ex: %% mcc\n",
    "            r'#[A-Za-z0-9]+$' #ending #_____\n",
    "           ]\n",
    "\n",
    "for p in patterns:\n",
    "    clean = clean.str.replace(p, ' ', regex=True)\n",
    "    clean = clean.str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "changed_mask = m != clean\n",
    "changed_items = m[changed_mask]\n",
    "changed_count = changed_mask.sum()\n",
    "\n",
    "print(\"Changed count:\", changed_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d008220d-f18b-4a32-8bbf-49331d0687ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_383/730543736.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  outflow_train['cleaned_memo'] = clean.fillna(outflow_train['memo'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>memo</th>\n",
       "      <th>cleaned_memo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TST* Casa Del Rio - Exp Fairlawn OH 09/24</td>\n",
       "      <td>tst* casa del rio - exp fairlawn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Buffalo Wild Wings</td>\n",
       "      <td>buffalo wild wings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Oculus CA 04/16</td>\n",
       "      <td>oculus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LOS GIRASOLES STOW OH 03/08</td>\n",
       "      <td>los girasoles stow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BUZZIS LAUNDRY 1 OH 03/28</td>\n",
       "      <td>buzzis laundry 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595705</th>\n",
       "      <td>PURCHASE 01-14 PUREKANA XXX-XXXXXXX  NJ VNT XXXX</td>\n",
       "      <td>purchase purekana vnt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595706</th>\n",
       "      <td>PURCHASE 01-18 WAL-MART #XXXX HUTCHINSON  KS S...</td>\n",
       "      <td>purchase wal-mart hutchinson srf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595708</th>\n",
       "      <td>PURCHASE 01-27 CLKBANK*MoonReading XXX-XXX-XXX...</td>\n",
       "      <td>purchase clkbank*moonreading vnt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595709</th>\n",
       "      <td>PURCHASE 01-26 CASH APP*DIANA STIE XXXXXXXXXX ...</td>\n",
       "      <td>purchase cash app*diana stie vnt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595710</th>\n",
       "      <td>PURCHASE 01-26 CASH APP*DIANA STIE XXXXXXXXXX ...</td>\n",
       "      <td>purchase cash app*diana stie vnt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1041442 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      memo  \\\n",
       "2                TST* Casa Del Rio - Exp Fairlawn OH 09/24   \n",
       "4                                       Buffalo Wild Wings   \n",
       "6                                          Oculus CA 04/16   \n",
       "7                              LOS GIRASOLES STOW OH 03/08   \n",
       "8                                BUZZIS LAUNDRY 1 OH 03/28   \n",
       "...                                                    ...   \n",
       "2595705   PURCHASE 01-14 PUREKANA XXX-XXXXXXX  NJ VNT XXXX   \n",
       "2595706  PURCHASE 01-18 WAL-MART #XXXX HUTCHINSON  KS S...   \n",
       "2595708  PURCHASE 01-27 CLKBANK*MoonReading XXX-XXX-XXX...   \n",
       "2595709  PURCHASE 01-26 CASH APP*DIANA STIE XXXXXXXXXX ...   \n",
       "2595710  PURCHASE 01-26 CASH APP*DIANA STIE XXXXXXXXXX ...   \n",
       "\n",
       "                             cleaned_memo  \n",
       "2        tst* casa del rio - exp fairlawn  \n",
       "4                      buffalo wild wings  \n",
       "6                                  oculus  \n",
       "7                      los girasoles stow  \n",
       "8                        buzzis laundry 1  \n",
       "...                                   ...  \n",
       "2595705             purchase purekana vnt  \n",
       "2595706  purchase wal-mart hutchinson srf  \n",
       "2595708  purchase clkbank*moonreading vnt  \n",
       "2595709  purchase cash app*diana stie vnt  \n",
       "2595710  purchase cash app*diana stie vnt  \n",
       "\n",
       "[1041442 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = clean.reindex(outflow_train.index)\n",
    "outflow_train['cleaned_memo'] = clean.fillna(outflow_train['memo'])\n",
    "outflow_train = outflow_train[['prism_consumer_id', 'prism_account_id', 'memo', 'cleaned_memo', 'amount', 'posted_date', 'category']]  \n",
    "outflow_train[outflow_train['cleaned_memo'] != outflow_train['memo']][['memo','cleaned_memo']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ed7126-30c9-4f8f-9b2d-53af8a82cf93",
   "metadata": {},
   "source": [
    "### Build n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4f86211-74b3-4dca-a5ee-344f4670ef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-gram\n",
    "def tokenize(text: str, lowercase: bool = True) -> List[str]:\n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "    # Keep words, numbers, and apostrophes; split by comma later\n",
    "    return re.findall(r\"[a-z0-9']+\", text)\n",
    "\n",
    "def generate_ngrams(tokens: List[str], n: int) -> Iterable[Tuple[str, ...]]:\n",
    "    \"\"\"Generate n-grams of size n from tokens.\"\"\"\n",
    "    if n <= 0:\n",
    "        raise ValueError(\"n must be >= 1\")\n",
    "    if len(tokens) < n:\n",
    "        return []\n",
    "    return zip(*[tokens[i:] for i in range(n)])\n",
    "\n",
    "def most_common_ngrams(\n",
    "    text: str,\n",
    "    n: int = 1,\n",
    "    top_k: int = 10,\n",
    "    stopwords: Optional[Iterable[str]] = None,\n",
    "    min_token_len: int = 1,\n",
    ") -> List[Tuple[str, int]]:\n",
    "    # Split the text into comma-separated segments\n",
    "    segments = [seg.strip() for seg in text.split(\",\") if seg.strip()]\n",
    "\n",
    "    all_tokens = []\n",
    "    for seg in segments:\n",
    "        tokens = tokenize(seg)\n",
    "        if stopwords:\n",
    "            sw = set(stopwords)\n",
    "            tokens = [t for t in tokens if t not in sw]\n",
    "        if min_token_len > 1:\n",
    "            tokens = [t for t in tokens if len(t) >= min_token_len]\n",
    "        all_tokens.append(tokens)\n",
    "\n",
    "    # Build all n-grams up to length n within each segment\n",
    "    grams = []\n",
    "    for tokens in all_tokens:\n",
    "        for i in range(1, n + 1):\n",
    "            grams.extend(\" \".join(g) for g in generate_ngrams(tokens, i))\n",
    "\n",
    "    counts = Counter(grams)\n",
    "    return counts.most_common(top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a725a3eb-3257-44b4-aa00-4e36326de1f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"tst* casa del rio - exp fairlawn, buffalo wild wings, oculus, los girasoles stow, buzzis laundry 1, tgi fridays stow, tst* the basement sp cuyahoga fall, lowe's, piada - 39, grubhub, hardees akron, market di state cuyahoga fall, swensons - montrose akron, great clips, apple, wing warehouse cuyah cuyahoga fall, winking lizard - 30, longhorn steak cuyahoga fall, on tap - cuyahoga fa cuyahoga fall, home depot, falls discount tobacc cuyahoga fls, burger king, o'charley's, homedepot, dairy queen, east of chicago - cu cuyahoga fall, giant-eag corpora uniontown, fin's bar & chill pigeon forge, acme no. 12 bai cuyahoga fall ohxxxxxx, taco bell, chick-fil-a, walmart, moe's sw grill cuyahoga fall, texas roadhouse, 39 piada cuyahoga fall, cleveland gaming fairview park, circle k, iah cnbc smartshop houston, bob evans rest stow, kohl's, moe's sw grill akron, wendy's, rays place of fairlawn fairlawn, get go st cuyahoga fall ohxxxxxx, dd doordash dashmart, chipotle mexican grill, swensons - north ak\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform n-gram to find most common patterns with <= n tokens\n",
    "\n",
    "# create corpus using all unique cleaned_memos in outflow_train\n",
    "memos = outflow_train[outflow_train['memo']!=outflow_train['category']]['cleaned_memo'].unique()\n",
    "memos = ', '.join(memos)\n",
    "memos[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1fad500-7958-4c72-8cd9-ece3292f6aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pos debit visa check card', 6856),\n",
       " ('pxxxxxxxxxxxxxxxxx card', 4003),\n",
       " ('purchase authorized on', 33710),\n",
       " ('sxxxxxxxxxxxxxxx card', 26726),\n",
       " ('debit visa check card', 6856),\n",
       " ('pxxxxxxxxxxxxxxx card', 5666),\n",
       " ('pos debit visa check', 6856),\n",
       " ('purchase authorized', 33710),\n",
       " ('debit card purchase', 6352),\n",
       " ('pxxxxxxxxxxxxxxxxx', 4003)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_grams = most_common_ngrams(memos, n=10, top_k=50)\n",
    "# longer patterns may include shorter patterns --> remove longer ones first\n",
    "sorted_by_len = sorted(n_grams, key=lambda x: len(x[0]), reverse = True)\n",
    "sorted_by_len[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0be5fe4a-efea-46b6-8db9-17dc6ca9f161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed count: 367753\n"
     ]
    }
   ],
   "source": [
    "m = outflow_train[outflow_train['memo']!=outflow_train['category']]['cleaned_memo'].str.lower()\n",
    "clean = m.copy(deep = True)\n",
    "\n",
    "patterns = [r'\\b(?:in)?\\s[sp]xxxxxxxxxxxxxxx\\scard',\n",
    "            r'\\b[sp]?x{3,}',\n",
    "            r'(?:purchase\\s)?authorized(?:\\son)?',\n",
    "            r'debit(?:\\scard)?',\n",
    "            r'visa\\s(?:check\\s)?card',\n",
    "            r'withdrawal',\n",
    "            r'recurring',\n",
    "            r'checkcard',\n",
    "            r'purchase',\n",
    "            r'^[^A-Za-z0-9]|\\-\\s',\n",
    "            r'\\#[a-zA-Z0-9]+\\s'\n",
    "           ]\n",
    "\n",
    "for p in patterns:\n",
    "    clean = clean.str.replace(p, ' ', regex=True)\n",
    "    clean = clean.str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "changed_mask = m != clean\n",
    "changed_items = m[changed_mask]\n",
    "changed_count = changed_mask.sum()\n",
    "\n",
    "print(\"Changed count:\", changed_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0bbb63-fbb5-473d-83c4-ddda69255d05",
   "metadata": {},
   "source": [
    "### check if any other common patterns can be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4933ca66-3e3d-4ce4-a7cb-1d1d621f9df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dollar general', 10898),\n",
       " (\"mcdonald's\", 29782),\n",
       " ('starbucks', 15166),\n",
       " ('cash app', 37056),\n",
       " ('doordash', 22096),\n",
       " ('7 eleven', 16599),\n",
       " ('wal mart', 16281),\n",
       " ('circle k', 12553),\n",
       " ('afterpay', 10472),\n",
       " ('point of', 10160)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memos = ', '.join(clean)\n",
    "\n",
    "max_len = int(outflow_train['cleaned_memo'].str.split().str.len().max())\n",
    "# find top 50 patterns with <= max_len tokens\n",
    "n_grams = most_common_ngrams(memos, n=max_len, top_k=50)\n",
    "# longer patterns may include shorter patterns --> remove longer ones first\n",
    "sorted_by_len = sorted(n_grams, key=lambda x: len(x[0]), reverse = True)\n",
    "sorted_by_len[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0a682a-0db4-4ace-b536-67b1a71872cb",
   "metadata": {},
   "source": [
    "### Use txt file to observe again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "484a4628-ac8c-49b5-b96a-6d40325dc66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed count: 380312\n"
     ]
    }
   ],
   "source": [
    "# np.savetxt(\"after_ngram_memos.txt\", np.sort(clean.unique()), fmt=\"%s\")\n",
    "\n",
    "patterns = [r'^\\d{2}\\-\\d{2}(?:\\-\\d{2,4})?\\b', #leading dates\n",
    "            r'c\\#\\sdbt\\scrd', #format ex: c# dbt crd\n",
    "            r'\\bc\\#?$', #ending c or c#\n",
    "            r'\\bcard#$', #ending card#\n",
    "            r'\\s[a-z]{0,2}x{3,}\\s', #ex: fxxxx, cxxxx\n",
    "           ]\n",
    "\n",
    "for p in patterns:\n",
    "    clean = clean.str.replace(p, ' ', regex=True)\n",
    "    clean = clean.str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "changed_mask = m != clean\n",
    "changed_items = m[changed_mask]\n",
    "changed_count = changed_mask.sum()\n",
    "\n",
    "print(\"Changed count:\", changed_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d26d50b1-90bc-45dd-90d2-7459a10fc3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>prism_account_id</th>\n",
       "      <th>memo</th>\n",
       "      <th>cleaned_memo</th>\n",
       "      <th>amount</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>TST* Casa Del Rio - Exp Fairlawn OH 09/24</td>\n",
       "      <td>tst* casa del rio exp fairlawn</td>\n",
       "      <td>18.42</td>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>Buffalo Wild Wings</td>\n",
       "      <td>buffalo wild wings</td>\n",
       "      <td>26.47</td>\n",
       "      <td>2022-09-12</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>Oculus CA 04/16</td>\n",
       "      <td>oculus</td>\n",
       "      <td>11.73</td>\n",
       "      <td>2022-04-18</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>LOS GIRASOLES STOW OH 03/08</td>\n",
       "      <td>los girasoles stow</td>\n",
       "      <td>30.04</td>\n",
       "      <td>2022-03-09</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>BUZZIS LAUNDRY 1 OH 03/28</td>\n",
       "      <td>buzzis laundry 1</td>\n",
       "      <td>4.16</td>\n",
       "      <td>2022-03-29</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prism_consumer_id prism_account_id  \\\n",
       "2                  0            acc_0   \n",
       "4                  0            acc_0   \n",
       "6                  0            acc_0   \n",
       "7                  0            acc_0   \n",
       "8                  0            acc_0   \n",
       "\n",
       "                                        memo                    cleaned_memo  \\\n",
       "2  TST* Casa Del Rio - Exp Fairlawn OH 09/24  tst* casa del rio exp fairlawn   \n",
       "4                         Buffalo Wild Wings              buffalo wild wings   \n",
       "6                            Oculus CA 04/16                          oculus   \n",
       "7                LOS GIRASOLES STOW OH 03/08              los girasoles stow   \n",
       "8                  BUZZIS LAUNDRY 1 OH 03/28                buzzis laundry 1   \n",
       "\n",
       "   amount posted_date             category  \n",
       "2   18.42  2022-09-26   FOOD_AND_BEVERAGES  \n",
       "4   26.47  2022-09-12   FOOD_AND_BEVERAGES  \n",
       "6   11.73  2022-04-18  GENERAL_MERCHANDISE  \n",
       "7   30.04  2022-03-09   FOOD_AND_BEVERAGES  \n",
       "8    4.16  2022-03-29  GENERAL_MERCHANDISE  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = clean.reindex(outflow_train.index)\n",
    "outflow_train['cleaned_memo'] = clean.fillna(outflow_train['memo'])\n",
    "outflow_train = outflow_train[['prism_consumer_id', 'prism_account_id', 'memo', 'cleaned_memo', 'amount', 'posted_date', 'category']]  \n",
    "outflow_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66525bf1-8e87-4b0e-a3d4-17eb4f4c6ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>memo</th>\n",
       "      <th>cleaned_memo</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7-Eleven</th>\n",
       "      <th>7-eleven</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFTERPAY XXX-XXXXXXX CA                      10/27</th>\n",
       "      <th>afterpay</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APPLE.COM/BILL XXX-XXX-XXXX CA               08/23</th>\n",
       "      <th>apple</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apple</th>\n",
       "      <th>apple</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Buy</th>\n",
       "      <th>best buy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CASH APP*DORIEEN CO XXX-XXX-XXXX AZ          03/24</th>\n",
       "      <th>cash app*dorieen</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CASH APP*MARLO</th>\n",
       "      <th>cash app*marlo</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHECKCARD XXXX AMERICAN AIRXXXXXXXXXXX FORT WORTH TX XXXXXXXXXXXXXXXXXXXXXXX</th>\n",
       "      <th>american airxxxxxxxxxxx fort worth</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHECKCARD XXXX Susdewitt Enterprises L XXX-XXXXXXX VA XXXXXXXXXXXXXXXXXXXXXXX</th>\n",
       "      <th>susdewitt enterprises l</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charleys Philly Steaks</th>\n",
       "      <th>charleys philly steaks</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chick-fil-A</th>\n",
       "      <th>chick-fil-a</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DBT CRD XXXX 05/14/22 XXXXXXX LITTLE FISHER SCRANTON      SC C#**XXXX</th>\n",
       "      <th>dbt crd little fisher scranton c#**</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DD DOORDASH ELPOLLOLO CA 12/27</th>\n",
       "      <th>dd doordash elpollolo</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEBIT CARD DEBIT / auth #XXXXXX 10-19-XXXX MJ S SPORTS BAR XXXX GULF BLVD STE ST PE Eff. Date: XXXXXXXXXXX</th>\n",
       "      <th>auth mj s sports bar gulf blvd ste st pe eff. date:</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dairy Queen</th>\n",
       "      <th>dairy queen</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Debit Purchase -visa Card XXXXapple Cash 1infinitelooca</th>\n",
       "      <th>apple cash 1infinitelooca</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doordash</th>\n",
       "      <th>doordash</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family Dollar</th>\n",
       "      <th>family dollar</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Imperial Services Inc</th>\n",
       "      <th>imperial services inc</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In &amp; Out</th>\n",
       "      <th>in &amp; out</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jodys Bakery</th>\n",
       "      <th>jodys bakery</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kroger</th>\n",
       "      <th>kroger</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LZC* LegalZoom.com CA 11/10</th>\n",
       "      <th>legalzoom</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lyft</th>\n",
       "      <th>lyft</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOBILE PURCHASE XXXX Subway XXXXX Houston TX XXXXXXXXXXXXXXXXXXXXXXX</th>\n",
       "      <th>mobile subway houston</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>McDonald's</th>\n",
       "      <th>mcdonald's</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meijer</th>\n",
       "      <th>meijer</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAYPAL INST XFER APPLE.COM BILL WEB ID: PAYPALSI77</th>\n",
       "      <th>apple</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS 624Z5C AMAZON.COM*1R9 SEATTLE WA ##XXXX</th>\n",
       "      <th>amazon</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS Debit - Visa Check Card XXXX - LOWE'S FOODS #1 APEX NC OTHA L KIMBROUGH POS TRANSACTION</th>\n",
       "      <th>pos lowe's foods apex otha l kimbrough pos transaction</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PURCHASE AUTHORIZED ON 01/01 DOLLAR GENERAL # DG XXXXX ELM MOTT TX PXXXXXXXXXXXXXXX CARD XXXX</th>\n",
       "      <th>dollar general # dg elm mott</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PURCHASE AUTHORIZED ON 02/27 eBay O*10-XXXXX-32 XXX-XXXXXXX CA SXXXXXXXXXXXXXXX CARD XXXX</th>\n",
       "      <th>ebay o*10 -32</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PURCHASE AUTHORIZED ON 03/28 THE CHAT LINE XXXXXXXXXX RI SXXXXXXXXXXXXXXX CARD XXXX</th>\n",
       "      <th>the chat line</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PURCHASE AUTHORIZED ON 08/10 Amazon Digit*QXXXX amzn.com/bill WA SXXXXXXXXXXXXXXX CARD XXXX</th>\n",
       "      <th>amzn</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PURCHASE AUTHORIZED ON 09/03 64 - SEPHORA XXXXX N D DALLAS TX PXXXXXXXXXXXXXXX CARD XXXX</th>\n",
       "      <th>64 sephora n d dallas</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PURCHASE AUTHORIZED ON 12/20 JAVI`S TACO SHACK MOON VISALIA CA PXXXXXXXXXXXXXXX CARD XXXX</th>\n",
       "      <th>javi`s taco shack moon visalia</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Popeyes</th>\n",
       "      <th>popeyes</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RECURRING PAYMENT AUTHORIZED ON 01/27 GOOGLE *Genjoy XXX-XXX-XXXX CA SXXXXXXXXXXXXXXX CARD XXXX</th>\n",
       "      <th>payment google *genjoy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sony Playstation</th>\n",
       "      <th>sony playstation</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steak 'n Shake</th>\n",
       "      <th>steak 'n shake</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taco Bell</th>\n",
       "      <th>taco bell</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trader Joe's</th>\n",
       "      <th>trader joe's</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAL-MART #XXXX DDA PIN POS PUR        CDXXXX TULSA OK#XXXXXXXXXXXX</th>\n",
       "      <th>wal-mart dda pin pos pur tulsa</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Walmart</th>\n",
       "      <th>walmart</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Withdrawal CONSUMER DEBIT / STARBUCKS STORE XXXXX FLORENCE SC Date 04/25/22 0 XXXXXXXXXX 0 XXXX %% Card 15 #XXXX %% MCC XXXX</th>\n",
       "      <th>consumer / starbucks store florence date 0 0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XXXX PUR AMAZON.COM 2V86A1U12 SEATTLE WA (11/29/21 10:25:19)</th>\n",
       "      <th>amazon</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XXXXXX PURCHASE Boehs Building S Fairview OK XXXXXXXX XXXXXX</th>\n",
       "      <th>boehs building s fairview</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       amount\n",
       "memo                                               cleaned_memo                                              \n",
       "7-Eleven                                           7-eleven                                                 2\n",
       "AFTERPAY XXX-XXXXXXX CA                      10/27 afterpay                                                 1\n",
       "APPLE.COM/BILL XXX-XXX-XXXX CA               08/23 apple                                                    1\n",
       "Apple                                              apple                                                    1\n",
       "Best Buy                                           best buy                                                 1\n",
       "CASH APP*DORIEEN CO XXX-XXX-XXXX AZ          03/24 cash app*dorieen                                         1\n",
       "CASH APP*MARLO                                     cash app*marlo                                           1\n",
       "CHECKCARD XXXX AMERICAN AIRXXXXXXXXXXX FORT WOR... american airxxxxxxxxxxx fort worth                       1\n",
       "CHECKCARD XXXX Susdewitt Enterprises L XXX-XXXX... susdewitt enterprises l                                  1\n",
       "Charleys Philly Steaks                             charleys philly steaks                                   1\n",
       "Chick-fil-A                                        chick-fil-a                                              1\n",
       "DBT CRD XXXX 05/14/22 XXXXXXX LITTLE FISHER SCR... dbt crd little fisher scranton c#**                      1\n",
       "DD DOORDASH ELPOLLOLO CA 12/27                     dd doordash elpollolo                                    1\n",
       "DEBIT CARD DEBIT / auth #XXXXXX 10-19-XXXX MJ S... auth mj s sports bar gulf blvd ste st pe eff. d...       1\n",
       "Dairy Queen                                        dairy queen                                              2\n",
       "Debit Purchase -visa Card XXXXapple Cash 1infin... apple cash 1infinitelooca                                1\n",
       "Doordash                                           doordash                                                 1\n",
       "Family Dollar                                      family dollar                                            1\n",
       "Imperial Services Inc                              imperial services inc                                    1\n",
       "In & Out                                           in & out                                                 1\n",
       "Jodys Bakery                                       jodys bakery                                             1\n",
       "Kroger                                             kroger                                                   1\n",
       "LZC* LegalZoom.com CA 11/10                        legalzoom                                                1\n",
       "Lyft                                               lyft                                                     1\n",
       "MOBILE PURCHASE XXXX Subway XXXXX Houston TX XX... mobile subway houston                                    1\n",
       "McDonald's                                         mcdonald's                                               1\n",
       "Meijer                                             meijer                                                   2\n",
       "PAYPAL INST XFER APPLE.COM BILL WEB ID: PAYPALSI77 apple                                                    1\n",
       "POS 624Z5C AMAZON.COM*1R9 SEATTLE WA ##XXXX        amazon                                                   1\n",
       "POS Debit - Visa Check Card XXXX - LOWE'S FOODS... pos lowe's foods apex otha l kimbrough pos tran...       1\n",
       "PURCHASE AUTHORIZED ON 01/01 DOLLAR GENERAL # D... dollar general # dg elm mott                             1\n",
       "PURCHASE AUTHORIZED ON 02/27 eBay O*10-XXXXX-32... ebay o*10 -32                                            1\n",
       "PURCHASE AUTHORIZED ON 03/28 THE CHAT LINE XXXX... the chat line                                            1\n",
       "PURCHASE AUTHORIZED ON 08/10 Amazon Digit*QXXXX... amzn                                                     1\n",
       "PURCHASE AUTHORIZED ON 09/03 64 - SEPHORA XXXXX... 64 sephora n d dallas                                    1\n",
       "PURCHASE AUTHORIZED ON 12/20 JAVI`S TACO SHACK ... javi`s taco shack moon visalia                           1\n",
       "Popeyes                                            popeyes                                                  1\n",
       "RECURRING PAYMENT AUTHORIZED ON 01/27 GOOGLE *G... payment google *genjoy                                   1\n",
       "Sony Playstation                                   sony playstation                                         1\n",
       "Steak 'n Shake                                     steak 'n shake                                           1\n",
       "Taco Bell                                          taco bell                                                1\n",
       "Trader Joe's                                       trader joe's                                             1\n",
       "WAL-MART #XXXX DDA PIN POS PUR        CDXXXX TU... wal-mart dda pin pos pur tulsa                           1\n",
       "Walmart                                            walmart                                                  1\n",
       "Withdrawal CONSUMER DEBIT / STARBUCKS STORE XXX... consumer / starbucks store florence date 0 0             1\n",
       "XXXX PUR AMAZON.COM 2V86A1U12 SEATTLE WA (11/29... amazon                                                   1\n",
       "XXXXXX PURCHASE Boehs Building S Fairview OK XX... boehs building s fairview                                1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outflow_train.sample(50).groupby(['memo','cleaned_memo'])[['amount']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75c3504b-6946-42e1-8197-b8204ba98cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_memos = np.sort(outflow_train[outflow_train['memo']!=outflow_train['category']]['cleaned_memo'].unique())\n",
    "# np.savetxt(\"cleaned_train_memos.txt\", clean_memos, fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8aef34a-4b3b-4dcf-a2b3-2aaa8539bd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>prism_account_id</th>\n",
       "      <th>memo</th>\n",
       "      <th>cleaned_memo</th>\n",
       "      <th>amount</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>763744</th>\n",
       "      <td>1617</td>\n",
       "      <td>acc_4488</td>\n",
       "      <td>XXX-XXX-XXXX</td>\n",
       "      <td></td>\n",
       "      <td>633.42</td>\n",
       "      <td>2021-09-17</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306986</th>\n",
       "      <td>672</td>\n",
       "      <td>acc_1961</td>\n",
       "      <td># XXXX</td>\n",
       "      <td></td>\n",
       "      <td>150.00</td>\n",
       "      <td>2022-01-19</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306988</th>\n",
       "      <td>672</td>\n",
       "      <td>acc_1961</td>\n",
       "      <td># XXXX</td>\n",
       "      <td></td>\n",
       "      <td>250.00</td>\n",
       "      <td>2022-05-26</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307058</th>\n",
       "      <td>672</td>\n",
       "      <td>acc_1961</td>\n",
       "      <td># XXXX</td>\n",
       "      <td></td>\n",
       "      <td>33.00</td>\n",
       "      <td>2022-03-18</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307066</th>\n",
       "      <td>672</td>\n",
       "      <td>acc_1961</td>\n",
       "      <td># XXXX</td>\n",
       "      <td></td>\n",
       "      <td>10.00</td>\n",
       "      <td>2022-05-27</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5128</th>\n",
       "      <td>12</td>\n",
       "      <td>acc_28</td>\n",
       "      <td>DEBIT CARD PURCHASE / | ON 10/03 AT TST SUNFLO...</td>\n",
       "      <td>| on at tst sunflower drive in| fair oaks |</td>\n",
       "      <td>35.59</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>12</td>\n",
       "      <td>acc_28</td>\n",
       "      <td>DEBIT CARD PURCHASE / | ON 09/15 AT TUG BOAT F...</td>\n",
       "      <td>| on at tug boat fish n chips 2| fair oaks |</td>\n",
       "      <td>45.75</td>\n",
       "      <td>2021-09-17</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5089</th>\n",
       "      <td>12</td>\n",
       "      <td>acc_28</td>\n",
       "      <td>DEBIT CARD PURCHASE / | ON 05/15 AT VINTAGE CH...</td>\n",
       "      <td>| on at vintage charm antiques| loomis |</td>\n",
       "      <td>158.02</td>\n",
       "      <td>2021-05-17</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5207</th>\n",
       "      <td>12</td>\n",
       "      <td>acc_28</td>\n",
       "      <td>DEBIT CARD PURCHASE / | ON 01/06 AT WAYSIDE LU...</td>\n",
       "      <td>| on at wayside lumber inc| |</td>\n",
       "      <td>262.18</td>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>12</td>\n",
       "      <td>acc_28</td>\n",
       "      <td>DEBIT CARD PURCHASE / | ON 04/12 AT WENDY S TR...</td>\n",
       "      <td>| on at wendy s trade ce| rancho cordov</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2021-04-12</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1041668 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        prism_consumer_id prism_account_id  \\\n",
       "763744               1617         acc_4488   \n",
       "306986                672         acc_1961   \n",
       "306988                672         acc_1961   \n",
       "307058                672         acc_1961   \n",
       "307066                672         acc_1961   \n",
       "...                   ...              ...   \n",
       "5128                   12           acc_28   \n",
       "4931                   12           acc_28   \n",
       "5089                   12           acc_28   \n",
       "5207                   12           acc_28   \n",
       "4796                   12           acc_28   \n",
       "\n",
       "                                                     memo  \\\n",
       "763744                                       XXX-XXX-XXXX   \n",
       "306986                                             # XXXX   \n",
       "306988                                             # XXXX   \n",
       "307058                                             # XXXX   \n",
       "307066                                             # XXXX   \n",
       "...                                                   ...   \n",
       "5128    DEBIT CARD PURCHASE / | ON 10/03 AT TST SUNFLO...   \n",
       "4931    DEBIT CARD PURCHASE / | ON 09/15 AT TUG BOAT F...   \n",
       "5089    DEBIT CARD PURCHASE / | ON 05/15 AT VINTAGE CH...   \n",
       "5207    DEBIT CARD PURCHASE / | ON 01/06 AT WAYSIDE LU...   \n",
       "4796    DEBIT CARD PURCHASE / | ON 04/12 AT WENDY S TR...   \n",
       "\n",
       "                                        cleaned_memo  amount posted_date  \\\n",
       "763744                                                633.42  2021-09-17   \n",
       "306986                                                150.00  2022-01-19   \n",
       "306988                                                250.00  2022-05-26   \n",
       "307058                                                 33.00  2022-03-18   \n",
       "307066                                                 10.00  2022-05-27   \n",
       "...                                              ...     ...         ...   \n",
       "5128     | on at tst sunflower drive in| fair oaks |   35.59  2020-10-05   \n",
       "4931    | on at tug boat fish n chips 2| fair oaks |   45.75  2021-09-17   \n",
       "5089        | on at vintage charm antiques| loomis |  158.02  2021-05-17   \n",
       "5207                   | on at wayside lumber inc| |  262.18  2021-01-07   \n",
       "4796         | on at wendy s trade ce| rancho cordov    3.45  2021-04-12   \n",
       "\n",
       "                   category  \n",
       "763744   FOOD_AND_BEVERAGES  \n",
       "306986   FOOD_AND_BEVERAGES  \n",
       "306988   FOOD_AND_BEVERAGES  \n",
       "307058   FOOD_AND_BEVERAGES  \n",
       "307066   FOOD_AND_BEVERAGES  \n",
       "...                     ...  \n",
       "5128     FOOD_AND_BEVERAGES  \n",
       "4931     FOOD_AND_BEVERAGES  \n",
       "5089    GENERAL_MERCHANDISE  \n",
       "5207    GENERAL_MERCHANDISE  \n",
       "4796     FOOD_AND_BEVERAGES  \n",
       "\n",
       "[1041668 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outflow_train.sort_values(by='cleaned_memo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6446997c-1b19-416e-8bdf-b25fde49eecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prism_consumer_id                   672\n",
       "prism_account_id               acc_1961\n",
       "memo                             # XXXX\n",
       "cleaned_memo                           \n",
       "amount                            150.0\n",
       "posted_date                  2022-04-28\n",
       "category             FOOD_AND_BEVERAGES\n",
       "Name: 307802, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outflow_train.loc[307802]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e723e0ef-b180-446e-8e8b-26690b9dbe99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>prism_account_id</th>\n",
       "      <th>memo</th>\n",
       "      <th>cleaned_memo</th>\n",
       "      <th>amount</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>TST* Casa Del Rio - Exp Fairlawn OH 09/24</td>\n",
       "      <td>tst* casa del rio exp fairlawn</td>\n",
       "      <td>18.42</td>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>Buffalo Wild Wings</td>\n",
       "      <td>buffalo wild wings</td>\n",
       "      <td>26.47</td>\n",
       "      <td>2022-09-12</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>Oculus CA 04/16</td>\n",
       "      <td>oculus</td>\n",
       "      <td>11.73</td>\n",
       "      <td>2022-04-18</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>LOS GIRASOLES STOW OH 03/08</td>\n",
       "      <td>los girasoles stow</td>\n",
       "      <td>30.04</td>\n",
       "      <td>2022-03-09</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>BUZZIS LAUNDRY 1 OH 03/28</td>\n",
       "      <td>buzzis laundry 1</td>\n",
       "      <td>4.16</td>\n",
       "      <td>2022-03-29</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595705</th>\n",
       "      <td>5939</td>\n",
       "      <td>acc_9522</td>\n",
       "      <td>PURCHASE 01-14 PUREKANA XXX-XXXXXXX  NJ VNT XXXX</td>\n",
       "      <td>purekana vnt</td>\n",
       "      <td>116.58</td>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595706</th>\n",
       "      <td>5939</td>\n",
       "      <td>acc_9522</td>\n",
       "      <td>PURCHASE 01-18 WAL-MART #XXXX HUTCHINSON  KS S...</td>\n",
       "      <td>wal-mart hutchinson srf</td>\n",
       "      <td>12.54</td>\n",
       "      <td>2023-01-18</td>\n",
       "      <td>GROCERIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595708</th>\n",
       "      <td>5939</td>\n",
       "      <td>acc_9522</td>\n",
       "      <td>PURCHASE 01-27 CLKBANK*MoonReading XXX-XXX-XXX...</td>\n",
       "      <td>clkbank*moonreading vnt</td>\n",
       "      <td>11.00</td>\n",
       "      <td>2023-01-27</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595709</th>\n",
       "      <td>5939</td>\n",
       "      <td>acc_9522</td>\n",
       "      <td>PURCHASE 01-26 CASH APP*DIANA STIE XXXXXXXXXX ...</td>\n",
       "      <td>cash app*diana stie vnt</td>\n",
       "      <td>16.00</td>\n",
       "      <td>2023-01-27</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595710</th>\n",
       "      <td>5939</td>\n",
       "      <td>acc_9522</td>\n",
       "      <td>PURCHASE 01-26 CASH APP*DIANA STIE XXXXXXXXXX ...</td>\n",
       "      <td>cash app*diana stie vnt</td>\n",
       "      <td>16.00</td>\n",
       "      <td>2023-01-27</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1041668 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         prism_consumer_id prism_account_id  \\\n",
       "2                        0            acc_0   \n",
       "4                        0            acc_0   \n",
       "6                        0            acc_0   \n",
       "7                        0            acc_0   \n",
       "8                        0            acc_0   \n",
       "...                    ...              ...   \n",
       "2595705               5939         acc_9522   \n",
       "2595706               5939         acc_9522   \n",
       "2595708               5939         acc_9522   \n",
       "2595709               5939         acc_9522   \n",
       "2595710               5939         acc_9522   \n",
       "\n",
       "                                                      memo  \\\n",
       "2                TST* Casa Del Rio - Exp Fairlawn OH 09/24   \n",
       "4                                       Buffalo Wild Wings   \n",
       "6                                          Oculus CA 04/16   \n",
       "7                              LOS GIRASOLES STOW OH 03/08   \n",
       "8                                BUZZIS LAUNDRY 1 OH 03/28   \n",
       "...                                                    ...   \n",
       "2595705   PURCHASE 01-14 PUREKANA XXX-XXXXXXX  NJ VNT XXXX   \n",
       "2595706  PURCHASE 01-18 WAL-MART #XXXX HUTCHINSON  KS S...   \n",
       "2595708  PURCHASE 01-27 CLKBANK*MoonReading XXX-XXX-XXX...   \n",
       "2595709  PURCHASE 01-26 CASH APP*DIANA STIE XXXXXXXXXX ...   \n",
       "2595710  PURCHASE 01-26 CASH APP*DIANA STIE XXXXXXXXXX ...   \n",
       "\n",
       "                           cleaned_memo  amount posted_date  \\\n",
       "2        tst* casa del rio exp fairlawn   18.42  2022-09-26   \n",
       "4                    buffalo wild wings   26.47  2022-09-12   \n",
       "6                                oculus   11.73  2022-04-18   \n",
       "7                    los girasoles stow   30.04  2022-03-09   \n",
       "8                      buzzis laundry 1    4.16  2022-03-29   \n",
       "...                                 ...     ...         ...   \n",
       "2595705                    purekana vnt  116.58  2023-01-17   \n",
       "2595706         wal-mart hutchinson srf   12.54  2023-01-18   \n",
       "2595708         clkbank*moonreading vnt   11.00  2023-01-27   \n",
       "2595709         cash app*diana stie vnt   16.00  2023-01-27   \n",
       "2595710         cash app*diana stie vnt   16.00  2023-01-27   \n",
       "\n",
       "                    category  \n",
       "2         FOOD_AND_BEVERAGES  \n",
       "4         FOOD_AND_BEVERAGES  \n",
       "6        GENERAL_MERCHANDISE  \n",
       "7         FOOD_AND_BEVERAGES  \n",
       "8        GENERAL_MERCHANDISE  \n",
       "...                      ...  \n",
       "2595705  GENERAL_MERCHANDISE  \n",
       "2595706            GROCERIES  \n",
       "2595708  GENERAL_MERCHANDISE  \n",
       "2595709  GENERAL_MERCHANDISE  \n",
       "2595710  GENERAL_MERCHANDISE  \n",
       "\n",
       "[1041668 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outflow_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5737c1a-d822-4ea6-84c3-706fd3a1cbed",
   "metadata": {},
   "source": [
    "## Week 4 (Feature Creation and Baseline Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0338d916-5df5-4e2c-9c39-d3df2a1fc5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outflow_train = create_amnt_feats(outflow_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e0152de-992e-40dd-9ace-33aca845248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.feature_extraction.holiday_feats import add_custom_holidays, holiday_context\n",
    "\n",
    "# 1️⃣ Define base holiday calendar\n",
    "years = range(\n",
    "    outflow_train['posted_date'].dt.year.min(),\n",
    "    outflow_train['posted_date'].dt.year.max() + 1\n",
    ")\n",
    "us_holidays = {d: name for y in years for d, name in holidays.UnitedStates(years=[y]).items()}\n",
    "\n",
    "# # 2️⃣ Add custom holidays like Black Friday & Cyber Monday\n",
    "# def add_custom_holidays(years):\n",
    "#     custom = {}\n",
    "#     for y in years:\n",
    "#         # Find Thanksgiving (4th Thursday of November)\n",
    "#         thanksgiving = [\n",
    "#             d for d, name in holidays.UnitedStates(years=[y]).items()\n",
    "#             if \"Thanksgiving\" in name\n",
    "#         ][0]\n",
    "\n",
    "#         # Custom additions\n",
    "#         black_friday = thanksgiving + timedelta(days=1)\n",
    "#         cyber_monday = black_friday + timedelta(days=3)\n",
    "\n",
    "#         custom[black_friday] = \"Black Friday\"\n",
    "#         custom[cyber_monday] = \"Cyber Monday\"\n",
    "#     return custom\n",
    "\n",
    "custom_holidays = add_custom_holidays(years)\n",
    "\n",
    "us_holidays = {\n",
    "    d: name\n",
    "    for y in years\n",
    "    for d, name in holidays.UnitedStates(years=[y]).items()\n",
    "}\n",
    "\n",
    "# Combine federal + custom holidays\n",
    "all_holidays = {**us_holidays, **custom_holidays}\n",
    "sorted_holidays = sorted(all_holidays.items(), key=lambda x: pd.Timestamp(x[0]))\n",
    "\n",
    "holiday_dates = [pd.Timestamp(d) for d, _ in sorted_holidays]\n",
    "holiday_names = [n for _, n in sorted_holidays]\n",
    "\n",
    "\n",
    "# # 3️⃣ Helper function to compute distances and names\n",
    "# def holiday_context(date):\n",
    "#     \"\"\"Compute holiday context using globally pre-sorted dates.\"\"\"\n",
    "    \n",
    "#     # find prev and next index using search\n",
    "#     prev_idx = max([i for i, h in enumerate(holiday_dates) if h <= date], default=None)\n",
    "#     next_idx = min([i for i, h in enumerate(holiday_dates) if h >= date], default=None)\n",
    "\n",
    "#     days_since_prev = (date - holiday_dates[prev_idx]).days if prev_idx is not None else None\n",
    "#     days_until_next = (holiday_dates[next_idx] - date).days if next_idx is not None else None\n",
    "    \n",
    "#     prev_name = holiday_names[prev_idx] if prev_idx is not None else None\n",
    "#     next_name = holiday_names[next_idx] if next_idx is not None else None\n",
    "\n",
    "#     return pd.Series({\n",
    "#         'days_since_prev_holiday': days_since_prev,\n",
    "#         'days_until_next_holiday': days_until_next,\n",
    "#         'prev_holiday': prev_name,\n",
    "#         'next_holiday': next_name\n",
    "#     })\n",
    "\n",
    "# Initialize pandarallel (enable tqdm progress bar)\n",
    "pandarallel.initialize(progress_bar=False, verbose=0)\n",
    "\n",
    "# Parallelized apply across CPU cores\n",
    "outflow_train[['days_since_prev_holiday', 'days_until_next_holiday',\n",
    "               'prev_holiday', 'next_holiday']] = (\n",
    "    outflow_train['posted_date']\n",
    "    .parallel_apply(lambda x: holiday_context(x, holiday_dates, holiday_names))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "918809ba-72dc-4070-8afe-201624162d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>prism_account_id</th>\n",
       "      <th>memo</th>\n",
       "      <th>cleaned_memo</th>\n",
       "      <th>amount</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>category</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>quarter</th>\n",
       "      <th>...</th>\n",
       "      <th>days_since_first_txn</th>\n",
       "      <th>whole_dollar</th>\n",
       "      <th>month_med_amnt</th>\n",
       "      <th>month_med_amnt_diff</th>\n",
       "      <th>amnt_zscore</th>\n",
       "      <th>log_amnt</th>\n",
       "      <th>days_since_prev_holiday</th>\n",
       "      <th>days_until_next_holiday</th>\n",
       "      <th>prev_holiday</th>\n",
       "      <th>next_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>TST* Casa Del Rio - Exp Fairlawn OH 09/24</td>\n",
       "      <td>tst* casa del rio exp fairlawn</td>\n",
       "      <td>18.42</td>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "      <td>Mon</td>\n",
       "      <td>September</td>\n",
       "      <td>q3</td>\n",
       "      <td>...</td>\n",
       "      <td>224</td>\n",
       "      <td>False</td>\n",
       "      <td>22.66</td>\n",
       "      <td>-4.24</td>\n",
       "      <td>-0.705843</td>\n",
       "      <td>2.966303</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>Labor Day</td>\n",
       "      <td>Columbus Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>Buffalo Wild Wings</td>\n",
       "      <td>buffalo wild wings</td>\n",
       "      <td>26.47</td>\n",
       "      <td>2022-09-12</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "      <td>Mon</td>\n",
       "      <td>September</td>\n",
       "      <td>q3</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>False</td>\n",
       "      <td>22.66</td>\n",
       "      <td>3.81</td>\n",
       "      <td>-0.288038</td>\n",
       "      <td>3.313095</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>Labor Day</td>\n",
       "      <td>Columbus Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>Oculus CA 04/16</td>\n",
       "      <td>oculus</td>\n",
       "      <td>11.73</td>\n",
       "      <td>2022-04-18</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "      <td>Mon</td>\n",
       "      <td>April</td>\n",
       "      <td>q2</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>False</td>\n",
       "      <td>26.68</td>\n",
       "      <td>-14.95</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.543961</td>\n",
       "      <td>56</td>\n",
       "      <td>42</td>\n",
       "      <td>Washington's Birthday</td>\n",
       "      <td>Memorial Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>LOS GIRASOLES STOW OH 03/08</td>\n",
       "      <td>los girasoles stow</td>\n",
       "      <td>30.04</td>\n",
       "      <td>2022-03-09</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "      <td>Wed</td>\n",
       "      <td>March</td>\n",
       "      <td>q1</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "      <td>26.19</td>\n",
       "      <td>3.85</td>\n",
       "      <td>-0.328565</td>\n",
       "      <td>3.435277</td>\n",
       "      <td>16</td>\n",
       "      <td>82</td>\n",
       "      <td>Washington's Birthday</td>\n",
       "      <td>Memorial Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>BUZZIS LAUNDRY 1 OH 03/28</td>\n",
       "      <td>buzzis laundry 1</td>\n",
       "      <td>4.16</td>\n",
       "      <td>2022-03-29</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "      <td>Tue</td>\n",
       "      <td>March</td>\n",
       "      <td>q1</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>False</td>\n",
       "      <td>26.19</td>\n",
       "      <td>-22.03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.640937</td>\n",
       "      <td>36</td>\n",
       "      <td>62</td>\n",
       "      <td>Washington's Birthday</td>\n",
       "      <td>Memorial Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595705</th>\n",
       "      <td>5939</td>\n",
       "      <td>acc_9522</td>\n",
       "      <td>PURCHASE 01-14 PUREKANA XXX-XXXXXXX  NJ VNT XXXX</td>\n",
       "      <td>purekana vnt</td>\n",
       "      <td>116.58</td>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "      <td>Tue</td>\n",
       "      <td>January</td>\n",
       "      <td>q1</td>\n",
       "      <td>...</td>\n",
       "      <td>713</td>\n",
       "      <td>False</td>\n",
       "      <td>19.48</td>\n",
       "      <td>97.10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.767119</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>Martin Luther King Jr. Day</td>\n",
       "      <td>Washington's Birthday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595706</th>\n",
       "      <td>5939</td>\n",
       "      <td>acc_9522</td>\n",
       "      <td>PURCHASE 01-18 WAL-MART #XXXX HUTCHINSON  KS S...</td>\n",
       "      <td>wal-mart hutchinson srf</td>\n",
       "      <td>12.54</td>\n",
       "      <td>2023-01-18</td>\n",
       "      <td>GROCERIES</td>\n",
       "      <td>Wed</td>\n",
       "      <td>January</td>\n",
       "      <td>q1</td>\n",
       "      <td>...</td>\n",
       "      <td>714</td>\n",
       "      <td>False</td>\n",
       "      <td>19.48</td>\n",
       "      <td>-6.94</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.605648</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>Martin Luther King Jr. Day</td>\n",
       "      <td>Washington's Birthday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595708</th>\n",
       "      <td>5939</td>\n",
       "      <td>acc_9522</td>\n",
       "      <td>PURCHASE 01-27 CLKBANK*MoonReading XXX-XXX-XXX...</td>\n",
       "      <td>clkbank*moonreading vnt</td>\n",
       "      <td>11.00</td>\n",
       "      <td>2023-01-27</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "      <td>Fri</td>\n",
       "      <td>January</td>\n",
       "      <td>q1</td>\n",
       "      <td>...</td>\n",
       "      <td>723</td>\n",
       "      <td>True</td>\n",
       "      <td>19.48</td>\n",
       "      <td>-8.48</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>Martin Luther King Jr. Day</td>\n",
       "      <td>Washington's Birthday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595709</th>\n",
       "      <td>5939</td>\n",
       "      <td>acc_9522</td>\n",
       "      <td>PURCHASE 01-26 CASH APP*DIANA STIE XXXXXXXXXX ...</td>\n",
       "      <td>cash app*diana stie vnt</td>\n",
       "      <td>16.00</td>\n",
       "      <td>2023-01-27</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "      <td>Fri</td>\n",
       "      <td>January</td>\n",
       "      <td>q1</td>\n",
       "      <td>...</td>\n",
       "      <td>723</td>\n",
       "      <td>True</td>\n",
       "      <td>19.48</td>\n",
       "      <td>-3.48</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>Martin Luther King Jr. Day</td>\n",
       "      <td>Washington's Birthday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595710</th>\n",
       "      <td>5939</td>\n",
       "      <td>acc_9522</td>\n",
       "      <td>PURCHASE 01-26 CASH APP*DIANA STIE XXXXXXXXXX ...</td>\n",
       "      <td>cash app*diana stie vnt</td>\n",
       "      <td>16.00</td>\n",
       "      <td>2023-01-27</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "      <td>Fri</td>\n",
       "      <td>January</td>\n",
       "      <td>q1</td>\n",
       "      <td>...</td>\n",
       "      <td>723</td>\n",
       "      <td>True</td>\n",
       "      <td>19.48</td>\n",
       "      <td>-3.48</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>Martin Luther King Jr. Day</td>\n",
       "      <td>Washington's Birthday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1041668 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         prism_consumer_id prism_account_id  \\\n",
       "2                        0            acc_0   \n",
       "4                        0            acc_0   \n",
       "6                        0            acc_0   \n",
       "7                        0            acc_0   \n",
       "8                        0            acc_0   \n",
       "...                    ...              ...   \n",
       "2595705               5939         acc_9522   \n",
       "2595706               5939         acc_9522   \n",
       "2595708               5939         acc_9522   \n",
       "2595709               5939         acc_9522   \n",
       "2595710               5939         acc_9522   \n",
       "\n",
       "                                                      memo  \\\n",
       "2                TST* Casa Del Rio - Exp Fairlawn OH 09/24   \n",
       "4                                       Buffalo Wild Wings   \n",
       "6                                          Oculus CA 04/16   \n",
       "7                              LOS GIRASOLES STOW OH 03/08   \n",
       "8                                BUZZIS LAUNDRY 1 OH 03/28   \n",
       "...                                                    ...   \n",
       "2595705   PURCHASE 01-14 PUREKANA XXX-XXXXXXX  NJ VNT XXXX   \n",
       "2595706  PURCHASE 01-18 WAL-MART #XXXX HUTCHINSON  KS S...   \n",
       "2595708  PURCHASE 01-27 CLKBANK*MoonReading XXX-XXX-XXX...   \n",
       "2595709  PURCHASE 01-26 CASH APP*DIANA STIE XXXXXXXXXX ...   \n",
       "2595710  PURCHASE 01-26 CASH APP*DIANA STIE XXXXXXXXXX ...   \n",
       "\n",
       "                           cleaned_memo  amount posted_date  \\\n",
       "2        tst* casa del rio exp fairlawn   18.42  2022-09-26   \n",
       "4                    buffalo wild wings   26.47  2022-09-12   \n",
       "6                                oculus   11.73  2022-04-18   \n",
       "7                    los girasoles stow   30.04  2022-03-09   \n",
       "8                      buzzis laundry 1    4.16  2022-03-29   \n",
       "...                                 ...     ...         ...   \n",
       "2595705                    purekana vnt  116.58  2023-01-17   \n",
       "2595706         wal-mart hutchinson srf   12.54  2023-01-18   \n",
       "2595708         clkbank*moonreading vnt   11.00  2023-01-27   \n",
       "2595709         cash app*diana stie vnt   16.00  2023-01-27   \n",
       "2595710         cash app*diana stie vnt   16.00  2023-01-27   \n",
       "\n",
       "                    category day_of_week      month quarter  ...  \\\n",
       "2         FOOD_AND_BEVERAGES         Mon  September      q3  ...   \n",
       "4         FOOD_AND_BEVERAGES         Mon  September      q3  ...   \n",
       "6        GENERAL_MERCHANDISE         Mon      April      q2  ...   \n",
       "7         FOOD_AND_BEVERAGES         Wed      March      q1  ...   \n",
       "8        GENERAL_MERCHANDISE         Tue      March      q1  ...   \n",
       "...                      ...         ...        ...     ...  ...   \n",
       "2595705  GENERAL_MERCHANDISE         Tue    January      q1  ...   \n",
       "2595706            GROCERIES         Wed    January      q1  ...   \n",
       "2595708  GENERAL_MERCHANDISE         Fri    January      q1  ...   \n",
       "2595709  GENERAL_MERCHANDISE         Fri    January      q1  ...   \n",
       "2595710  GENERAL_MERCHANDISE         Fri    January      q1  ...   \n",
       "\n",
       "         days_since_first_txn  whole_dollar  month_med_amnt  \\\n",
       "2                         224         False           22.66   \n",
       "4                         210         False           22.66   \n",
       "6                          63         False           26.68   \n",
       "7                          23         False           26.19   \n",
       "8                          43         False           26.19   \n",
       "...                       ...           ...             ...   \n",
       "2595705                   713         False           19.48   \n",
       "2595706                   714         False           19.48   \n",
       "2595708                   723          True           19.48   \n",
       "2595709                   723          True           19.48   \n",
       "2595710                   723          True           19.48   \n",
       "\n",
       "         month_med_amnt_diff  amnt_zscore  log_amnt  days_since_prev_holiday  \\\n",
       "2                      -4.24    -0.705843  2.966303                       21   \n",
       "4                       3.81    -0.288038  3.313095                        7   \n",
       "6                     -14.95     0.000000  2.543961                       56   \n",
       "7                       3.85    -0.328565  3.435277                       16   \n",
       "8                     -22.03     0.000000  1.640937                       36   \n",
       "...                      ...          ...       ...                      ...   \n",
       "2595705                97.10     0.000000  4.767119                        1   \n",
       "2595706                -6.94     0.000000  2.605648                        2   \n",
       "2595708                -8.48     0.000000  2.484907                       11   \n",
       "2595709                -3.48     0.000000  2.833213                       11   \n",
       "2595710                -3.48     0.000000  2.833213                       11   \n",
       "\n",
       "         days_until_next_holiday                prev_holiday  \\\n",
       "2                             14                   Labor Day   \n",
       "4                             28                   Labor Day   \n",
       "6                             42       Washington's Birthday   \n",
       "7                             82       Washington's Birthday   \n",
       "8                             62       Washington's Birthday   \n",
       "...                          ...                         ...   \n",
       "2595705                       34  Martin Luther King Jr. Day   \n",
       "2595706                       33  Martin Luther King Jr. Day   \n",
       "2595708                       24  Martin Luther King Jr. Day   \n",
       "2595709                       24  Martin Luther King Jr. Day   \n",
       "2595710                       24  Martin Luther King Jr. Day   \n",
       "\n",
       "                  next_holiday  \n",
       "2                 Columbus Day  \n",
       "4                 Columbus Day  \n",
       "6                 Memorial Day  \n",
       "7                 Memorial Day  \n",
       "8                 Memorial Day  \n",
       "...                        ...  \n",
       "2595705  Washington's Birthday  \n",
       "2595706  Washington's Birthday  \n",
       "2595708  Washington's Birthday  \n",
       "2595709  Washington's Birthday  \n",
       "2595710  Washington's Birthday  \n",
       "\n",
       "[1041668 rows x 24 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outflow_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2e59155-5d4a-44a4-8f5d-1ff8accbc7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_450/3126451093.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  outflow_train_feat['amnt_zscore'].replace([np.inf, -np.inf], 0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "outflow_train_feat['amnt_zscore'].replace([np.inf, -np.inf], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8bc6fb30-f410-41e7-9b15-dbb2bd34c8f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "columns are missing: {'cleaned_memo'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 54\u001b[0m\n\u001b[1;32m     49\u001b[0m pipe\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mcat_cols\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mnum_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_score(y_test, y_pred))\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/pipeline.py:602\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 602\u001b[0m         Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    605\u001b[0m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:1003\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m   1001\u001b[0m     diff \u001b[38;5;241m=\u001b[39m all_names \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(column_names)\n\u001b[1;32m   1002\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m diff:\n\u001b[0;32m-> 1003\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns are missing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1005\u001b[0m     \u001b[38;5;66;03m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[1;32m   1006\u001b[0m     \u001b[38;5;66;03m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: columns are missing: {'cleaned_memo'}"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# -------------------------\n",
    "# Identify your feature columns\n",
    "# -------------------------\n",
    "text_col = \"cleaned_memo\"\n",
    "\n",
    "cat_cols = [\"day_of_week\", \"month\", \"quarter\", \"year\", \"whole_dollar\"]\n",
    "num_cols = [\n",
    "    \"days_since_prev\",\n",
    "    \"avg_days_between_txn\",\n",
    "    \"rolling_avg_days_between_txn\",\n",
    "    \"days_since_first_txn\",\n",
    "    \"month_med_amnt\",\n",
    "    \"month_med_amnt_diff\",\n",
    "    \"amnt_zscore\",\n",
    "    \"log_amnt\"\n",
    "]\n",
    "X_train = outflow_train_feat\n",
    "y_train = outflow_train_feat['category']\n",
    "X_test = outflow_test_feat\n",
    "y_test = outflow_test_feat['category']\n",
    "# -------------------------\n",
    "# Create Preprocessing\n",
    "# -------------------------\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"text\", TfidfVectorizer(max_features=1000, ngram_range=(1, 5)), text_col),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Full Pipeline\n",
    "# -------------------------\n",
    "pipe = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# -------------------------\n",
    "# Train\n",
    "# -------------------------\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Predict\n",
    "# -------------------------\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e7db246-398b-49b1-9090-92ac4171a155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any NaN?:\n",
      "days_since_prev                 False\n",
      "avg_days_between_txn            False\n",
      "rolling_avg_days_between_txn    False\n",
      "days_since_first_txn            False\n",
      "month_med_amnt                  False\n",
      "month_med_amnt_diff             False\n",
      "amnt_zscore                     False\n",
      "log_amnt                        False\n",
      "dtype: bool\n",
      "\n",
      "Any infinity?:\n",
      "days_since_prev                 False\n",
      "avg_days_between_txn            False\n",
      "rolling_avg_days_between_txn    False\n",
      "days_since_first_txn            False\n",
      "month_med_amnt                  False\n",
      "month_med_amnt_diff             False\n",
      "amnt_zscore                     False\n",
      "log_amnt                        False\n",
      "dtype: bool\n",
      "\n",
      "Which columns have inf?:\n"
     ]
    }
   ],
   "source": [
    "print(\"Any NaN?:\")\n",
    "print(outflow_test_feat[num_cols].isna().any())\n",
    "\n",
    "print(\"\\nAny infinity?:\")\n",
    "print(np.isinf(outflow_test_feat[num_cols]).any())\n",
    "\n",
    "print(\"\\nWhich columns have inf?:\")\n",
    "for col in num_cols:\n",
    "    if np.isinf(outflow_test_feat[col]).any():\n",
    "        print(\"INF in:\", col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b95d1a-417b-41ad-9327-8613a812c324",
   "metadata": {},
   "source": [
    "### TFIDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e21269d3-e7f0-42b0-b96e-74687accf54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    max_features=100,\n",
    "    ngram_range=(1, 5)\n",
    ")\n",
    "tfidf_matrix = tfidf.fit_transform(outflow_train['cleaned_memo'])\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(),\n",
    "    columns=tfidf.get_feature_names_out()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cc2a282-9504-4859-91ed-1e9cb10be3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['365', '365 market', '888', 'ach', 'afterpay', 'amazon', 'amzn', 'and',\n",
       "       'app', 'apple', 'bell', 'burger', 'burger king', 'ca', 'cafe', 'card',\n",
       "       'cash', 'cash app', 'chick', 'chick fil', 'circle', 'city', 'costco',\n",
       "       'crd', 'date', 'dbt', 'dd', 'dd doordash', 'dda', 'depot', 'dollar',\n",
       "       'dollar general', 'donuts', 'doordash', 'dunkin', 'eats', 'eleven',\n",
       "       'family', 'fil', 'food', 'from', 'general', 'google', 'home',\n",
       "       'home depot', 'in', 'inc', 'king', 'kroger', 'liquor', 'lyft', 'market',\n",
       "       'mart', 'mart super', 'mcdonald', 'mobile', 'new', 'of', 'of sale',\n",
       "       'on', 'payment', 'paypal', 'pin', 'pizza', 'point', 'point of',\n",
       "       'point of sale', 'pos', 'pos transaction', 'publix', 'pur', 'safeway',\n",
       "       'sale', 'san', 'signature', 'sq', 'st', 'starbucks', 'store', 'super',\n",
       "       'taco', 'taco bell', 'target', 'the', 'transaction', 'tst', 'uber',\n",
       "       'uber eats', 'us', 'usa', 'vending', 'visa', 'wal', 'wal mart',\n",
       "       'wal mart super', 'walmart', 'web', 'wendy', 'wm', 'www'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4d97deb-50c4-47a2-948b-5017d55712ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tfidf = tfidf_matrix.mean(axis=0).A1\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "tfidf_importance = (\n",
    "    pd.DataFrame({'term': feature_names, 'mean_tfidf': mean_tfidf})\n",
    "    .sort_values(by='mean_tfidf', ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cfe4087-ba38-4465-89a7-18e1756221c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>mean_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>amazon</td>\n",
       "      <td>0.049251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>apple</td>\n",
       "      <td>0.042388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.039540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>mcdonald</td>\n",
       "      <td>0.030863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>walmart</td>\n",
       "      <td>0.026600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cash</td>\n",
       "      <td>0.024033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>card</td>\n",
       "      <td>0.023740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>amzn</td>\n",
       "      <td>0.021223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>app</td>\n",
       "      <td>0.020763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cash app</td>\n",
       "      <td>0.019698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>uber</td>\n",
       "      <td>0.017173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>eleven</td>\n",
       "      <td>0.014399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>target</td>\n",
       "      <td>0.014336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>google</td>\n",
       "      <td>0.013576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>starbucks</td>\n",
       "      <td>0.013296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>dollar</td>\n",
       "      <td>0.012995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>payment</td>\n",
       "      <td>0.012538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>market</td>\n",
       "      <td>0.012343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>circle</td>\n",
       "      <td>0.011386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>doordash</td>\n",
       "      <td>0.011112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         term  mean_tfidf\n",
       "5      amazon    0.049251\n",
       "9       apple    0.042388\n",
       "67        pos    0.039540\n",
       "54   mcdonald    0.030863\n",
       "95    walmart    0.026600\n",
       "16       cash    0.024033\n",
       "15       card    0.023740\n",
       "6        amzn    0.021223\n",
       "8         app    0.020763\n",
       "17   cash app    0.019698\n",
       "86       uber    0.017173\n",
       "36     eleven    0.014399\n",
       "82     target    0.014336\n",
       "42     google    0.013576\n",
       "77  starbucks    0.013296\n",
       "30     dollar    0.012995\n",
       "60    payment    0.012538\n",
       "51     market    0.012343\n",
       "20     circle    0.011386\n",
       "33   doordash    0.011112"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_importance.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "875c24aa-22cf-4293-8543-394a6f5795a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features=10, accuracy=0.517\n",
      "max_features=50, accuracy=0.706\n",
      "max_features=100, accuracy=0.736\n",
      "max_features=500, accuracy=0.823\n",
      "max_features=1000, accuracy=0.859\n"
     ]
    }
   ],
   "source": [
    "X = outflow_train_add['cleaned_memo']\n",
    "y = outflow_train_add['category']\n",
    "\n",
    "max_features_list = [10, 50, 100, 500, 1000]\n",
    "scores = []\n",
    "\n",
    "for n in max_features_list:\n",
    "    pipe = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=n, ngram_range=(1, 5))),\n",
    "        ('clf', LogisticRegression(max_iter=200))\n",
    "    ])\n",
    "    \n",
    "    score = cross_val_score(pipe, X, y, cv=min(3, len(outflow_train)), scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "    print(f\"max_features={n}, accuracy={score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66069beb-f2c5-4728-b37e-073dfeea5bb4",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47adb0b3-d084-4aa6-b7ee-fbf31491d323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8679975678196863\n",
      "\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "          EDUCATION       0.71      0.03      0.06       999\n",
      " FOOD_AND_BEVERAGES       0.85      0.88      0.86     99154\n",
      "GENERAL_MERCHANDISE       0.85      0.89      0.87    101953\n",
      "          GROCERIES       0.95      0.86      0.90     45523\n",
      "           MORTGAGE       0.80      0.18      0.30       404\n",
      "          OVERDRAFT       0.98      0.96      0.97       737\n",
      "               PETS       0.99      0.72      0.84      2454\n",
      "               RENT       0.71      0.53      0.61       479\n",
      "             TRAVEL       0.88      0.74      0.80     13080\n",
      "\n",
      "           accuracy                           0.87    264783\n",
      "          macro avg       0.86      0.64      0.69    264783\n",
      "       weighted avg       0.87      0.87      0.87    264783\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = outflow_train_add['cleaned_memo']\n",
    "y = outflow_train_add['category']\n",
    "X_test = outflow_test[\"memo\"]\n",
    "y_test = outflow_test[\"category\"]\n",
    "pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=1000, ngram_range=(1, 5))),  # TF-IDF features\n",
    "    ('clf', LogisticRegression(max_iter=300, n_jobs=-1))                 # Logistic regression classifier\n",
    "])\n",
    "\n",
    "#Train the Model\n",
    "pipe.fit(X, y)\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53d2799b-402a-4a6a-a4fd-e65f63696115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9232050395984637\n",
      "\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "          EDUCATION       0.73      0.39      0.51       999\n",
      " FOOD_AND_BEVERAGES       0.91      0.93      0.92     99154\n",
      "GENERAL_MERCHANDISE       0.91      0.93      0.92    101953\n",
      "          GROCERIES       0.96      0.93      0.94     45523\n",
      "           MORTGAGE       1.00      0.46      0.63       404\n",
      "          OVERDRAFT       0.99      0.97      0.98       737\n",
      "               PETS       1.00      0.84      0.91      2454\n",
      "               RENT       0.83      0.67      0.74       479\n",
      "             TRAVEL       0.98      0.88      0.93     13080\n",
      "\n",
      "           accuracy                           0.92    264783\n",
      "          macro avg       0.92      0.78      0.83    264783\n",
      "       weighted avg       0.92      0.92      0.92    264783\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 3))),  # TF-IDF features\n",
    "    ('clf', LogisticRegression(max_iter=300, n_jobs=-1))                 # Logistic regression classifier\n",
    "])\n",
    "\n",
    "#Train the Model\n",
    "pipe.fit(X, y)\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "# report train and test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfbb7146-faaa-4cb9-95b2-8047aa70b28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X does not contain any features, but ColumnTransformer is expecting 9 features",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/base.py:420\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m \u001b[43m_num_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:345\u001b[0m, in \u001b[0;36m_num_features\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m    344\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 345\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(message)\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: Unable to find the number of features from X of type pandas.core.series.Series with shape (264783,)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m pipe\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_score(y_test, y_pred))\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/pipeline.py:602\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 602\u001b[0m         Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    605\u001b[0m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:1007\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m   1003\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns are missing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1005\u001b[0m     \u001b[38;5;66;03m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[1;32m   1006\u001b[0m     \u001b[38;5;66;03m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[0;32m-> 1007\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _routing_enabled():\n\u001b[1;32m   1010\u001b[0m     routed_params \u001b[38;5;241m=\u001b[39m process_routing(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/base.py:423\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reset \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 423\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    424\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX does not contain any features, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    425\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is expecting \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    426\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    427\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;66;03m# If the number of features is not defined and reset=True,\u001b[39;00m\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;66;03m# then we skip this check\u001b[39;00m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: X does not contain any features, but ColumnTransformer is expecting 9 features"
     ]
    }
   ],
   "source": [
    "text_col = 'cleaned_memo'\n",
    "num_cols = ['amount', 'days_since_prev', 'avg_days_between_txn',\n",
    "            'rolling_avg_days_between_txn']\n",
    "cat_cols = ['day_of_week', 'month', 'quarter', 'year']\n",
    "\n",
    "# Combine all features\n",
    "X = outflow_train_add[[text_col] + num_cols + cat_cols]\n",
    "y = outflow_train_add['category']\n",
    "X_test = outflow_test['memo']\n",
    "y_test = outflow_test['category']\n",
    "\n",
    "# Preprocessing for each column type\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', TfidfVectorizer(max_features=1000, ngram_range=(1, 5)), text_col),\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the pipeline\n",
    "pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', LogisticRegression(max_iter=300, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipe.fit(X, y)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b77d232-75bf-4556-86c0-26d5f7ba202a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
